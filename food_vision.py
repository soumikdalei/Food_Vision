# -*- coding: utf-8 -*-
"""Food_Vision.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/github/soumikdalei/Food_Vision/blob/main/Food_Vision.ipynb
"""

!wget https://raw.githubusercontent.com/soumikdalei/Food_Vision/refs/heads/main/helper_function.py

from helper_function import create_tensorboard_callback, plot_loss_curves, compare_historys

import tensorflow_datasets as tfds
(train_data, test_data), ds_info = tfds.load(name="food101",
                                             split=["train", "validation"],
                                             shuffle_files=True,
                                             as_supervised=True,
                                             with_info=True)

class_names = ds_info.features["label"].names
class_names[:10]

def preprocess_img(image, label, img_shape=224):

    image = tf.image.resize(image, [img_shape, img_shape]) #
    return tf.cast(image, tf.float32), label

import tensorflow as tf
train_data = train_data.map(map_func=preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)
train_data = train_data.shuffle(buffer_size=1000).batch(batch_size=32).prefetch(buffer_size=tf.data.AUTOTUNE)
test_data = test_data.map(preprocess_img, num_parallel_calls=tf.data.AUTOTUNE)
test_data = test_data.batch(32).prefetch(tf.data.AUTOTUNE)

from helper_function import create_tensorboard_callback


checkpoint_path = "model_checkpoints/cp.weights.h5"
model_checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,
                                                      monitor="val_accuracy",
                                                      save_best_only=True,
                                                      save_weights_only=True,
                                                      verbose=0)

from tensorflow.keras import mixed_precision
mixed_precision.set_global_policy(policy="mixed_float16")

mixed_precision.global_policy()

from tensorflow.keras import layers


input_shape = (224, 224, 3)
base_model = tf.keras.applications.EfficientNetB0(include_top=False)
base_model.trainable = False


inputs = layers.Input(shape=input_shape, name="input_layer")

x = base_model(inputs, training=False)
x = layers.GlobalAveragePooling2D(name="pooling_layer")(x)
x = layers.Dense(len(class_names))(x)

outputs = layers.Activation("softmax", dtype=tf.float32, name="softmax_float32")(x)
model = tf.keras.Model(inputs, outputs)


model.compile(loss="sparse_categorical_crossentropy",
              optimizer=tf.keras.optimizers.Lion(learning_rate=0.0001),
              metrics=["accuracy"])

model.summary()

history_101_food_classes_feature_extract = model.fit(train_data,
                                                     epochs=3,
                                                     steps_per_epoch=len(train_data),
                                                     validation_data=test_data,
                                                     validation_steps=int(0.15 * len(test_data)),
                                                     callbacks=[create_tensorboard_callback("training_logs",
                                                                                            "efficientnetb0_101_classes_all_data_feature_extract"),
                                                                model_checkpoint])

results_feature_extract_model = model.evaluate(test_data)
results_feature_extract_model

plot_loss_curves(history_101_food_classes_feature_extract)

base_model.trainable = True

for layer in base_model.layers[:-20]:
    layer.trainable = False


model.compile(loss="sparse_categorical_crossentropy",
              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001/10),
              metrics=["accuracy"])

fine_tune_epochs = 10
history_101_food_classes_fine_tune = model.fit(train_data,
                                               epochs=fine_tune_epochs,
                                               steps_per_epoch=len(train_data),
                                               validation_data=test_data,
                                               validation_steps=int(0.15 * len(test_data)),
                                               initial_epoch=history_101_food_classes_feature_extract.epoch[-1],
                                               callbacks=[create_tensorboard_callback("training_logs",
                                                                                      "efficientnetb0_101_classes_all_data_fine_tuning"),
                                                          model_checkpoint])

model.evaluate(test_data)

plot_loss_curves(history_101_food_classes_fine_tune)

compare_historys(original_history=history_101_food_classes_feature_extract,
                 new_history=history_101_food_classes_fine_tune,
                 initial_epochs=3)

def predict_on_custom_image(image_path, model, class_names, img_shape=224):

    img = tf.io.read_file(image_path)
    img = tf.image.decode_image(img, channels=3)
    img = tf.image.convert_image_dtype(img, tf.float32)
    img = tf.image.resize(img, size=[img_shape, img_shape])
    img = tf.expand_dims(img, axis=0)

    prediction = model.predict(img)
    predicted_class_index = tf.argmax(prediction, axis=1)[0].numpy()
    predicted_class_name = class_names[predicted_class_index]
    prediction_probability = tf.reduce_max(prediction).numpy()

    return predicted_class_name, prediction_probability

custom_image_path = "/content/images (1).jpeg"
predicted_class, probability = predict_on_custom_image(custom_image_path, model, class_names)
print(f"Predicted class: {predicted_class}, Probability: {probability:.4f}")

y_pred=model.predict(test_data)
y_pred=tf.argmax(y_pred,axis=1)
y_pred

import itertools
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix

# Our function needs a different name to sklearn's plot_confusion_matrix
def make_confusion_matrix(y_true, y_pred, classes=None, figsize=(100, 100), text_size=15, norm=False, savefig=False):

  cm = confusion_matrix(y_true, y_pred)
  cm_norm = cm.astype("float") / cm.sum(axis=1)[:, np.newaxis] # normalize it
  n_classes = cm.shape[0]
  fig, ax = plt.subplots(figsize=figsize)
  cax = ax.matshow(cm, cmap=plt.cm.Blues)
  fig.colorbar(cax)


  if classes:
    labels = classes
  else:
    labels = np.arange(cm.shape[0])


  ax.set(title="Confusion Matrix",
         xlabel="Predicted label",
         ylabel="True label",
         xticks=np.arange(n_classes),
         yticks=np.arange(n_classes),
         xticklabels=labels,
         yticklabels=labels)


  ax.xaxis.set_label_position("bottom")
  ax.xaxis.tick_bottom()


  plt.xticks(rotation=70, fontsize=text_size)
  plt.yticks(fontsize=text_size)

  threshold = (cm.max() + cm.min()) / 2.


  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
    if norm:
      plt.text(j, i, f"{cm[i, j]} ({cm_norm[i, j]*100:.1f}%)",
              horizontalalignment="center",
              color="white" if cm[i, j] > threshold else "black",
              size=text_size)
    else:
      plt.text(j, i, f"{cm[i, j]}",
              horizontalalignment="center",
              color="white" if cm[i, j] > threshold else "black",
              size=text_size)


  if savefig:
    fig.savefig("confusion_matrix.png")

y_true = [label.numpy() for image, label in test_data.unbatch()]
make_confusion_matrix(y_true=y_true,
                      y_pred=y_pred,
                      classes=class_names)